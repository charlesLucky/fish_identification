{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  os\n",
    "import  tensorflow as tf\n",
    "import  numpy as np\n",
    "from    tensorflow import keras\n",
    "from    tensorflow.keras import datasets, layers, optimizers, models\n",
    "from    tensorflow.keras import regularizers\n",
    "from utils import LoadFishDataUtil\n",
    "from tensorflow.keras.utils import plot_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading train data and generate the data config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir ='/media/xingbo/Storage/fish_identification/data/SESSION_TENT/SESSION1'\n",
    "BATCH_SIZE = 8\n",
    "IMG_SIZE=160\n",
    "IMG_WIDTH=320\n",
    "IMG_HEIGHT=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myloadData = LoadFishDataUtil(data_dir,BATCH_SIZE,IMG_WIDTH,IMG_HEIGHT)\n",
    "train_dataset,val_dataset,test_dataset,STEPS_PER_EPOCH, CLASS_NAMES,class_num = myloadData.loadFishData()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(keras.Model):\n",
    "\n",
    "\n",
    "    def __init__(self, input_shape,num_classes):\n",
    "        \"\"\"\n",
    "\n",
    "        :param input_shape: [32, 32, 3]\n",
    "        \"\"\"\n",
    "        super(VGG16, self).__init__()\n",
    "\n",
    "        weight_decay = 0.000\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        model = models.Sequential()\n",
    "\n",
    "        model.add(layers.Conv2D(64, (3, 3), padding='same',\n",
    "                         input_shape=input_shape, kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.3))\n",
    "\n",
    "        model.add(layers.Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(layers.Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.4))\n",
    "\n",
    "        model.add(layers.Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(layers.Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.4))\n",
    "\n",
    "        model.add(layers.Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.4))\n",
    "\n",
    "        model.add(layers.Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "        model.add(layers.Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.4))\n",
    "\n",
    "        model.add(layers.Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.4))\n",
    "\n",
    "        model.add(layers.Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "        model.add(layers.Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.4))\n",
    "\n",
    "        model.add(layers.Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.4))\n",
    "\n",
    "        model.add(layers.Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(layers.Dropout(0.5))\n",
    "\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "        model.add(layers.Dropout(0.5))\n",
    "        model.add(layers.Dense(self.num_classes))\n",
    "        # model.add(layers.Activation('softmax'))\n",
    "\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "        x = self.model(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = class_num\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "validation_steps = 20\n",
    "# build model and optimizer\n",
    "model = VGG16([IMG_WIDTH,IMG_HEIGHT, 3],class_num)\n",
    "model.compile(optimizer=keras.optimizers.Adam(0.001),\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.build(input_shape=(None, IMG_WIDTH,IMG_HEIGHT, 3))\n",
    "\n",
    "model.load_weights('model/vggfish20191121TENT.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_model(model)     # 画出模型结构图，并保存成图片,to_file = 'a simple convnet.png'\n",
    "print(model.summary())                                 # 打印模型概况\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#【1】创建一个新model, 使得它的输出(outputs)是 VGG19 中任意层的输出(output)\n",
    "model2 = models.Model(inputs=model.input, outputs=model.get_layer('block4_pool').output)\n",
    "print(model2.summary())                                 # 打印模型概况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir ='/home/xingbo/Desktop/fish_identification/data/SESSION_TENT/SESSION1'\n",
    "#test_data_dir ='/home/xingbo/Desktop/fish_identification/data/SESSION_AQUARIUM/SESSION_test'\n",
    "BATCH_SIZE = 8\n",
    "IMG_SIZE=160\n",
    "SPLIT_WEIGHTS = (0, 0, 1) # Data prepare split wight train vs validation vs test\n",
    "testloadData = LoadFishDataUtil(test_data_dir,BATCH_SIZE,IMG_SIZE,CLASS_NAMES,SPLIT_WEIGHTS)\n",
    "sess2_train_dataset,sess2_val_dataset,sess2_test_dataset,sess2_STEPS_PER_EPOCH, sess2_CLASS_NAMES,sess2_class_num = testloadData.loadFishData()\n",
    "\n",
    "#sess2_test_dataset,sess2_class_num = testloadData.loadTestFishData()\n",
    "loss0,accuracy0 = model.evaluate(sess2_test_dataset, steps = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_data_dir ='/home/xingbo/Desktop/fish_identification/data/SESSION_TANT/SESSION1'\n",
    "#test_data_dir ='/home/xingbo/Desktop/fish_identification/data/SESSION_AQUARIUM/SESSION_test'\n",
    "BATCH_SIZE = 8\n",
    "IMG_SIZE=160\n",
    "testloadData = LoadFishDataUtil(test_data_dir,BATCH_SIZE,IMG_SIZE,CLASS_NAMES)\n",
    "sess2_test_dataset,sess2_class_num = testloadData.loadTestFishData()\n",
    "loss0,accuracy0 = model.evaluate(sess2_test_dataset, steps = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from    tensorflow.keras import datasets, layers, optimizers, models\n",
    "from    tensorflow.keras import regularizers\n",
    "\n",
    "model = models.Sequential() # 顺序模型\n",
    "\n",
    "# 输入层\n",
    "model.add(layers.Dense(7, input_shape=(4,)))  # Dense就是常用的全连接层\n",
    "model.add(layers.Activation('sigmoid')) # 激活函数\n",
    "\n",
    "# 隐层\n",
    "model.add(layers.Dense(13))  # Dense就是常用的全连接层\n",
    "model.add(layers.Activation('sigmoid')) # 激活函数\n",
    "\n",
    "# 输出层\n",
    "model.add(layers.Dense(5))\n",
    "model.add(layers.Activation('softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from    tensorflow.keras import datasets, layers, optimizers, models\n",
    "from    tensorflow.keras import regularizers\n",
    "model = models.Sequential() # 顺序模型\n",
    "# input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
