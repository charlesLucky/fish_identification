{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import  tensorflow as tf\n",
    "from    tensorflow import  keras\n",
    "from    tensorflow.keras import datasets, layers, optimizers, models\n",
    "from    tensorflow.keras import regularizers\n",
    "import  os\n",
    "\n",
    "import  argparse\n",
    "import  numpy as np\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import IPython.display as display\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pathlib\n",
    "\n",
    "\n",
    "class LoadFishDataUtil():\n",
    "    def __init__(self, directory_str,BATCH_SIZE,IMG_SIZE):\n",
    "      self.directory_str=directory_str\n",
    "      self.BATCH_SIZE=BATCH_SIZE\n",
    "      self.IMG_SIZE=IMG_SIZE\n",
    "      self.data_dir = pathlib.Path(directory_str)\n",
    "      self.image_count = len(list(self.data_dir.glob('*/*.png')))\n",
    "      self.CLASS_NAMES = np.array([item.name for item in self.data_dir.glob('*') if item.name != \"LICENSE.txt\"])\n",
    "      self.class_num=len(self.CLASS_NAMES)\n",
    " \n",
    "      IMG_HEIGHT = IMG_SIZE\n",
    "      IMG_WIDTH = IMG_SIZE\n",
    "      self.STEPS_PER_EPOCH = np.ceil(self.image_count/BATCH_SIZE)\n",
    "\n",
    "\n",
    "    def get_label(self,file_path):\n",
    "    # convert the path to a list of path components\n",
    "      parts = tf.strings.split(file_path, '/')\n",
    "    # The second to last is the class-directory\n",
    "      print(parts[-2] == self.CLASS_NAMES)\n",
    "      wh = tf.where(tf.equal(self.CLASS_NAMES,parts[-2]))\n",
    "      return parts[-2] == self.CLASS_NAMES\n",
    "    def decode_img(self,img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "      img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "      img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    #img = (img/127.5) - 1\n",
    "    # resize the image to the desired size.\n",
    "      return tf.image.resize(img, [self.IMG_SIZE, self.IMG_SIZE])\n",
    "\n",
    "    def process_path(self,file_path):\n",
    "      label = self.get_label(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "      img = tf.io.read_file(file_path)\n",
    "      img = self.decode_img(img)\n",
    "      return img, label\n",
    " \n",
    "\n",
    "    def prepare_for_training(self,ds, cache=True, shuffle_buffer_size=1000):\n",
    "    # This is a small dataset, only load it once, and keep it in memory.\n",
    "    # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
    "    # fit in memory.\n",
    "      if cache:\n",
    "        if isinstance(cache, str):\n",
    "          ds = ds.cache(cache)\n",
    "        else:\n",
    "          ds = ds.cache()\n",
    "\n",
    "      ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "\n",
    "    # Repeat forever\n",
    "      ds = ds.repeat()\n",
    "\n",
    "      ds = ds.batch(self.BATCH_SIZE)\n",
    "\n",
    "  # `prefetch` lets the dataset fetch batches in the background while the model\n",
    "  # is training.\n",
    "      ds = ds.prefetch(buffer_size=self.AUTOTUNE)\n",
    "\n",
    "      return ds\n",
    "  \n",
    "\n",
    "    def loadFishData(self):\n",
    "      list_ds = tf.data.Dataset.list_files(str(self.data_dir/'*/*'))\n",
    "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "      self.AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "      self.labeled_ds = list_ds.map(self.process_path, num_parallel_calls=self.AUTOTUNE)\n",
    "   \n",
    "      train_size = int(0.7 * self.image_count)\n",
    "      val_size = int(0.15 * self.image_count)\n",
    "      test_size = int(0.15 * self.image_count)\n",
    "      train_ds = self.prepare_for_training(self.labeled_ds)\n",
    "\n",
    "      full_dataset = train_ds.shuffle(buffer_size=1000,reshuffle_each_iteration = False )\n",
    "      train_dataset = full_dataset.take(train_size)\n",
    "      test_dataset = full_dataset.skip(train_size)\n",
    "      val_dataset = test_dataset.skip(val_size)\n",
    "      test_dataset = test_dataset.take(test_size)\n",
    "      return train_dataset,val_dataset,test_dataset,self.STEPS_PER_EPOCH,self.CLASS_NAMES,self.class_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir ='/home/xingbo/Desktop/fish_identification/data/SESSION_AQUARIUM/SESSION1'\n",
    "BATCH_SIZE = 8\n",
    "IMG_SIZE=160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myloadData = LoadFishDataUtil(data_dir,BATCH_SIZE,IMG_SIZE)\n",
    "train_dataset,val_dataset,test_dataset,STEPS_PER_EPOCH, CLASS_NAMES,class_num = myloadData.loadFishData()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(models.Model):\n",
    "\n",
    "\n",
    "    def __init__(self, input_shape,num_classes):\n",
    "        \"\"\"\n",
    "\n",
    "        :param input_shape: [32, 32, 3]\n",
    "        \"\"\"\n",
    "        super(VGG16, self).__init__()\n",
    "\n",
    "        weight_decay = 0.000\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        model = models.Sequential()\n",
    "\n",
    "        model.add(layers.Conv2D(64, (3, 3), padding='same',\n",
    "                         input_shape=input_shape, kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.3))\n",
    "\n",
    "        model.add(layers.Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(layers.Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.4))\n",
    "\n",
    "        model.add(layers.Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(layers.Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.4))\n",
    "\n",
    "        model.add(layers.Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.4))\n",
    "\n",
    "        model.add(layers.Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "        model.add(layers.Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.4))\n",
    "\n",
    "        model.add(layers.Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.4))\n",
    "\n",
    "        model.add(layers.Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "        model.add(layers.Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.4))\n",
    "\n",
    "        model.add(layers.Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.4))\n",
    "\n",
    "        model.add(layers.Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(layers.Dropout(0.5))\n",
    "\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "        model.add(layers.Dropout(0.5))\n",
    "        model.add(layers.Dense(self.num_classes))\n",
    "        # model.add(layers.Activation('softmax'))\n",
    "\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "        x = self.model(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model=VGG16(input_shape=[IMG_SIZE, IMG_SIZE, 3],include_top=False, weights='imagenet', classes=class_num)\n",
    "for image_batch, label_batch in train_dataset.take(1):\n",
    "   pass\n",
    "\n",
    "image_batch.shape\n",
    "feature_batch = base_model(image_batch)\n",
    "print(feature_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction\n",
    "You will freeze the convolutional base created from the previous step and use that as a feature extractor, add a classifier on top of it and train the top-level classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze the convolutional base\n",
    "It's important to freeze the convolutional based before you compile and train the model. By freezing (or setting `layer.trainable = False`), you prevent the weights in a given layer from being updated during training. MobileNet V2 has many layers, so setting the entire model's trainable flag to `False` will freeze all the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "# Let's take a look at the base model architecture\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a classification head\n",
    "\n",
    "Apply a `tf.keras.layers.Dense` layer to convert these features into a single prediction per image. You don't need an activation function here because this prediction will be treated as a `logit`, or a raw prediction value.  Positive numbers predict class 1, negative numbers predict class 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)\n",
    "\n",
    "prediction_layer = keras.layers.Dense(class_num, activation=K.relu)\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "print(prediction_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "    global_average_layer,\n",
    "  prediction_layer\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# must specify from_logits=True!\n",
    "criteon = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "metric = keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "base_learning_rate = 0.01\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
    "              loss=criteon,\n",
    "              metrics=[metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## let's train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_epochs = 100\n",
    "validation_steps = 20\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=initial_epochs,\n",
    "                    validation_data=val_dataset,validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#model = VGG16([IMG_SIZE, IMG_SIZE, 3], class_num)\n",
    "\n",
    "# must specify from_logits=True!\n",
    "criteon = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "metric = keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "for epoch in range(250):\n",
    "\n",
    "    for step, (x, y) in enumerate(train_dataset):\n",
    "        # [b, 1] => [b]\n",
    "        y = tf.squeeze(y, axis=1)\n",
    "        # [b, 10]\n",
    "        y = tf.one_hot(y, depth=class_num)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x)\n",
    "            loss = criteon(y, logits)\n",
    "            # loss2 = compute_loss(logits, tf.argmax(y, axis=1))\n",
    "            # mse_loss = tf.reduce_sum(tf.square(y-logits))\n",
    "            # print(y.shape, logits.shape)\n",
    "            metric.update_state(y, logits)\n",
    "\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        # MUST clip gradient here or it will disconverge!\n",
    "        grads = [tf.clip_by_norm(g, 15) for g in grads]\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if step % 40 == 0:\n",
    "            # for g in grads:\n",
    "            #     print(tf.norm(g).numpy())\n",
    "            print(epoch, step, 'loss:', float(loss), 'acc:', metric.result().numpy())\n",
    "            metric.reset_states()\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "\n",
    "        metric = keras.metrics.CategoricalAccuracy()\n",
    "        for x, y in val_dataset:\n",
    "            # [b, 1] => [b]\n",
    "            y = tf.squeeze(y, axis=1)\n",
    "            # [b, 10]\n",
    "            y = tf.one_hot(y, depth=class_num)\n",
    "\n",
    "            logits = model.predict(x)\n",
    "            # be careful, these functions can accept y as [b] without warnning.\n",
    "            metric.update_state(y, logits)\n",
    "        print('test acc:', metric.result().numpy())\n",
    "        metric.reset_states()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
