{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import  os\n",
    "import  tensorflow as tf\n",
    "import  numpy as np\n",
    "from    tensorflow import keras\n",
    "from utils import LoadFishDataUtil\n",
    "from    tensorflow.keras import datasets, layers, optimizers, models\n",
    "from    tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import pathlib\n",
    "import h5py\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_datasets as tfds\n",
    "import random\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total images: 3327\n"
     ]
    }
   ],
   "source": [
    "#data_dir ='/media/xingbo/Storage/fish_identification/data/SESSION_TENT/SESSION1'\n",
    "data_dir ='/media/xingbo/Storage/fish_identification/data/SESSION_AQUARIUM/SESSION_MERGE/SESSION1'\n",
    "data_dir_path = pathlib.Path(data_dir)\n",
    "image_count = len(list(data_dir_path.glob('*/*.png')))\n",
    "print('total images:',image_count)\n",
    "BATCH_SIZE = 8\n",
    "IMG_SIZE=160\n",
    "IMG_WIDTH=28\n",
    "IMG_HEIGHT=28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total class: 328\n"
     ]
    }
   ],
   "source": [
    "CLASS_NAMES=None\n",
    "SPLIT_WEIGHTS=(0.7, 0.3, 0.0)# train cv val vs test\n",
    "myloadData = LoadFishDataUtil(data_dir,BATCH_SIZE,IMG_WIDTH,IMG_HEIGHT,CLASS_NAMES,SPLIT_WEIGHTS)\n",
    "train_dataset,val_dataset,test_dataset,STEPS_PER_EPOCH, CLASS_NAMES,class_num = myloadData.loadFishDataWithname()\n",
    "input_shape=(IMG_WIDTH,IMG_HEIGHT, 1)\n",
    "print('total class:',class_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset_num_elements 2328, val_dataset_num_elements 998, test_dataset_num_elements 0\n"
     ]
    }
   ],
   "source": [
    "train_dataset_num_elements = tf.data.experimental.cardinality(train_dataset).numpy()\n",
    "val_dataset_num_elements = tf.data.experimental.cardinality(val_dataset).numpy()\n",
    "test_dataset_num_elements = tf.data.experimental.cardinality(test_dataset).numpy()\n",
    "print(f\"train_dataset_num_elements {train_dataset_num_elements}, val_dataset_num_elements {val_dataset_num_elements}, test_dataset_num_elements {test_dataset_num_elements}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay = 0.000\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), padding='same', input_shape=input_shape,\n",
    "                        kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.4))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.4))\n",
    "\n",
    "model.add(layers.Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.4))\n",
    "\n",
    "model.add(layers.Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.4))\n",
    "\n",
    "model.add(layers.Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.4))\n",
    "\n",
    "model.add(layers.Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.4))\n",
    "\n",
    "model.add(layers.Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.4))\n",
    "\n",
    "model.add(layers.Conv2D(512, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "#model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1024, kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.Dense(256, kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "\n",
    "#model.add(layers.Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=input_shape),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation=None), # No activation on final dense layer\n",
    "    tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) # L2 normalize embeddings\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize_img(img, label):\n",
    "    img = tf.cast(img, tf.float32) / 255.\n",
    "    #print(label)\n",
    "    return (img, label)\n",
    "\n",
    "train_dataset, test_dataset = tfds.load(name=\"mnist\", split=['train', 'test'], as_supervised=True)\n",
    "train_dataset\n",
    "# Build your input pipelines\n",
    "train_dataset = train_dataset.shuffle(1024).batch(32)\n",
    "train_dataset = train_dataset.map(_normalize_img)\n",
    "\n",
    "test_dataset = test_dataset.batch(32)\n",
    "test_dataset = test_dataset.map(_normalize_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "base_path= '/media/xingbo/Storage/fish_identification/data/SESSION_AQUARIUM/SESSION_MERGE/SESSION1/'\n",
    "IMG_TYPES = ['.png', '.jpg']\n",
    "def load_data(path=data_dir):\n",
    "    directories = os.listdir(path)\n",
    "    #print(directories)\n",
    "    img = {}\n",
    "    for directory in directories:\n",
    "        cur_path = os.path.join(base_path, directory)\n",
    "        #print(cur_path)\n",
    "        _, _, filenames = next(os.walk(cur_path))\n",
    "        for filename in filenames:\n",
    "            if os.path.splitext(filename)[1] in IMG_TYPES:\n",
    "                if directory not in img:\n",
    "                    img[directory ] = [os.path.join(base_path + directory , filename)]\n",
    "                else:\n",
    "                    img[directory].append(\n",
    "                        os.path.join(base_path + directory , filename))\n",
    "\n",
    "    label_encode = le.fit_transform(list(img.keys()))\n",
    "    return img, label_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions 11 and 12 are not compatible",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-0787eb8359cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_encode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msplitting_point\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_encode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplitting_point\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    433\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \"\"\"\n\u001b[0;32m--> 435\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   \u001b[0;32mclass\u001b[0m \u001b[0m_GeneratorState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m   2362\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2363\u001b[0m       batch_dim.assert_is_compatible_with(tensor_shape.Dimension(\n\u001b[0;32m-> 2364\u001b[0;31m           tensor_shape.dimension_value(t.get_shape()[0])))\n\u001b[0m\u001b[1;32m   2365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2366\u001b[0m     variant_tensor = gen_dataset_ops.tensor_slice_dataset(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m       raise ValueError(\"Dimensions %s and %s are not compatible\" %\n\u001b[0;32m--> 275\u001b[0;31m                        (self, other))\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mmerge_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions 11 and 12 are not compatible"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "img, label_encode = load_data(data_dir)\n",
    "inc = iter(img.items())\n",
    "splitting_point = int(len(label_encode)*0.8)\n",
    "x_train = dict(islice(inc, splitting_point))\n",
    "x_test = dict(inc)\n",
    "y_train = label_encode[:splitting_point]\n",
    "y_test = label_encode[splitting_point:]\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "img, label_encode = load_data(data_dir)\n",
    "\n",
    "def tfdata_generator(images, labels, is_training, batch_size=128):\n",
    "    '''Construct a data generator using tf.Dataset'''\n",
    "    num_labels = len(images)\n",
    "    def preprocess_fn(filename, label):\n",
    "        '''A transformation function to preprocess raw data\n",
    "        into trainable input. '''\n",
    "        image_string = tf.io.read_file(filename)\n",
    "\n",
    "        #Don't use tf.image.decode_image, or the output shape will be undefined\n",
    "        image = tf.image.decode_png(image_string, channels=3)\n",
    "\n",
    "        #This will convert to float values in [0, 1]\n",
    "        image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "\n",
    "        resized_image = tf.image.resize(image, [IMG_WIDTH, IMG_HEIGHT])\n",
    "        return resized_image, label\n",
    "\n",
    "\n",
    "    def generator():\n",
    "        while True:\n",
    "            # Sample the labels that will compose the batch\n",
    "            chosen_labels = random.sample(range(num_labels),\n",
    "                                        num_classes_per_batch)\n",
    "            for label in chosen_labels:\n",
    "                for _ in range(num_images_per_class):\n",
    "                    # yield images[label][np.random.choice(range(num_images_per_class))]\n",
    "                    yield label_encode[label]\n",
    "\n",
    "    datasets = []\n",
    "    for i in range(len(img)):\n",
    "        filenames = img[le.inverse_transform([i])[0]]\n",
    "        labels = [i for _ in range(len(filenames))]\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "        datasets.append(dataset)\n",
    "    \n",
    "    # dataset = [tf.data.Dataset.from_tensor_slices((images, label_encode))]\n",
    "\n",
    "    choice_dataset = tf.data.Dataset.from_generator(generator, tf.int64)\n",
    "    # for d in choice_dataset:\n",
    "    #     print(d)\n",
    "    dataset = tf.data.experimental.choose_from_datasets(datasets, choice_dataset)\n",
    "    # for image_number, label in dataset.batch(4).take(20):\n",
    "    #     print(\"images {} from classes {}\".format(image_number.numpy(), label.numpy()))\n",
    "    dataset = dataset.map(preprocess_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True if is_training else False)\n",
    "\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.prefetch(1)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "inc = iter(img.items())\n",
    "splitting_point = int(len(label_encode)*0.8)\n",
    "x_train = dict(islice(inc, splitting_point))\n",
    "x_test = dict(inc)\n",
    "y_train = label_encode[:splitting_point]\n",
    "y_test = label_encode[splitting_point:]\n",
    "train_dataset = tfdata_generator(x_train, y_train, is_training=True)\n",
    "val_dataset = tfdata_generator(x_test, y_test, is_training=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "      img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "      img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    #img = (img/127.5) - 1\n",
    "    # resize the image to the desired size.\n",
    "      return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n",
    "    \n",
    "    def process_path_withname(file_path):\n",
    "      label = get_label_withname(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "      img = tf.io.read_file(file_path)\n",
    "      img = decode_img(img)\n",
    "      #label=label.astype('int64')\n",
    "      return img, label\n",
    "    \n",
    "    def get_label_withname(file_path):\n",
    "    # convert the path to a list of path components\n",
    "      parts = tf.strings.split(file_path, '/')\n",
    "      #file_path=tf.dtypes.cast(file_path, tf.int64)\n",
    "      #parts= file_path.split(os.sep)\n",
    "\n",
    "    # The second to last is the class-directory\n",
    "      \n",
    "      wh = tf.where(tf.equal(CLASS_NAMES,parts[-2]))\n",
    "      return wh\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ds = tf.data.Dataset.list_files(str(data_dir+'/*/*'))\n",
    "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "labeled_ds = list_ds.map(process_path_withname, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "   \n",
    "train_size = int(0.7* image_count)\n",
    "val_size = int(0.3 * image_count)\n",
    "ds = labeled_ds.cache()\n",
    "ds = ds.batch(BATCH_SIZE)\n",
    "ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "ds = ds.shuffle(buffer_size=1000,reshuffle_each_iteration = False )\n",
    "        # Build your input pipelines\n",
    "train_dataset = ds.take(train_size)\n",
    "test_dataset = ds.skip(train_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 7, 7, 256)         295168    \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 7, 7, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 7, 7, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 3, 3, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 1, 1, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 1, 1, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 1, 1, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               262400    \n",
      "=================================================================\n",
      "Total params: 15,522,240\n",
      "Trainable params: 15,511,744\n",
      "Non-trainable params: 10,496\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build model and optimizer\n",
    "#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "model.compile(optimizer=keras.optimizers.Adam(0.001),\n",
    "              loss=tfa.losses.TripletSemiHardLoss()\n",
    "              #loss=keras.losses.CategoricalCrossentropy(from_logits=True), metrics=['accuracy']\n",
    "             )\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.utils import plot_model\n",
    "#plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "inc = iter(train_dataset)\n",
    "while True:\n",
    "    try:\n",
    "        image_batch, label_batch = next(inc)\n",
    "        imgs = image_batch.numpy()\n",
    "        labels = label_batch.numpy()\n",
    "        for i in range(len(imgs)):\n",
    "            #print(imgs[i])\n",
    "            print(labels[i])\n",
    "            n = n + 1\n",
    "            #print(n)\n",
    "    except:\n",
    "        break\n",
    "   \n",
    "\n",
    "print(n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 2.6365\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 4.2109\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 1.9637\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 1.1281\n",
      "Epoch 5/50\n",
      "1349/1875 [====================>.........] - ETA: 7s - loss: 1.7303"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-924ccf77d4d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m history=model.fit(train_dataset, \n\u001b[0;32m----> 8\u001b[0;31m                   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                   \u001b[0;31m#steps_per_epoch=100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                   \u001b[0;31m#callbacks=[callback],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "validation_steps = 20\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "# This callback will stop the training when there is no improvement in\n",
    "# the validation loss for three consecutive epochs.\n",
    "# train\n",
    "history=model.fit(train_dataset, \n",
    "                  epochs=epochs\n",
    "                  #steps_per_epoch=100\n",
    "                  #callbacks=[callback],\n",
    "          #validation_data=val_dataset,verbose=1\n",
    "                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate on test set\n",
    "#scores = model.evaluate(test_dataset, verbose=1)\n",
    "#print(\"Final test loss and accuracy :\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(test_dataset)\n",
    "# Save test embeddings for visualization in projector\n",
    "np.savetxt(\"vecs.tsv\", results, delimiter='\\t')\n",
    "\n",
    "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
    "for img, labels in tfds.as_numpy(test_dataset):\n",
    "    [out_m.write(str(x) + \"\\n\") for x in labels]\n",
    "out_m.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "# model.save('vggfish.h5py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model/vggfish20191125AQU_MERGE.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model/vggfish20191125AQU_MERGE.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract feature\n",
    "## SESSION3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_data_dir ='/media/xingbo/Storage/fish_identification/data/SESSION_AQUARIUM/SESSION3'\n",
    "BATCH_SIZE = 8\n",
    "testloadData = LoadFishDataUtil(test_data_dir,BATCH_SIZE,IMG_WIDTH,IMG_HEIGHT,CLASS_NAMES)\n",
    "sess2_test_dataset,sess2_class_num = testloadData.loadTestFishData()\n",
    "test_num_elements = tf.data.experimental.cardinality(sess2_test_dataset).numpy()\n",
    "print(f\"we have total {test_num_elements} batches of images for testing, around {test_num_elements*BATCH_SIZE} samples\")\n",
    "# evaluate on test set\n",
    "#scores = model.evaluate(sess2_test_dataset, verbose=1)\n",
    "#print(\"Final test loss and accuracy :\", scores)\n",
    "from numpy import linalg as LA\n",
    "feats = []\n",
    "names = []\n",
    "feature_model = models.Model(inputs=model.input, outputs=model.get_layer('batch_normalization_13').output)\n",
    "n = 0\n",
    "for image_batch, label_batch in sess2_test_dataset:\n",
    "    feature=model(image_batch)\n",
    "    \n",
    "    #print(n)\n",
    "    #print(feature.shape[0])\n",
    "    for i in range(feature.shape[0]):\n",
    "        n=n+1\n",
    "        feats.append(feature[i])\n",
    "        names.append(np.argwhere(label_batch[i]).ravel())\n",
    "        indxmax=np.argmax(feature[i])\n",
    "        #print('predictions max index:',indxmax)\n",
    "        #print('predictions:', CLASS_NAMES[indxmax] )\n",
    "        #print('real:', CLASS_NAMES[np.argwhere(label_batch[i]).ravel()])\n",
    "       \n",
    "print(f\"finanly we have {n} samples extracted features\")\n",
    "feats3 = np.array(feats)\n",
    "names3 = np.array(names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir ='/media/xingbo/Storage/fish_identification/data/SESSION_AQUARIUM/SESSION2'\n",
    "BATCH_SIZE = 8\n",
    "testloadData = LoadFishDataUtil(test_data_dir,BATCH_SIZE,IMG_WIDTH,IMG_HEIGHT,CLASS_NAMES)\n",
    "sess2_test_dataset,sess2_class_num = testloadData.loadTestFishData()\n",
    "test_num_elements = tf.data.experimental.cardinality(sess2_test_dataset).numpy()\n",
    "print(f\"we have total {test_num_elements} batches of images for testing, around {test_num_elements*BATCH_SIZE} samples\")\n",
    "\n",
    "feats = []\n",
    "names = []\n",
    "feature_model = models.Model(inputs=model.input, outputs=model.get_layer('batch_normalization_13').output)\n",
    "n = 0\n",
    "for image_batch, label_batch in sess2_test_dataset:\n",
    "    feature=model(image_batch)\n",
    "    for i in range(feature.shape[0]):\n",
    "        n=n+1\n",
    "        feats.append(feature[i])\n",
    "        names.append(np.argwhere(label_batch[i]).ravel())\n",
    "        indxmax=np.argmax(feature[i])\n",
    "       \n",
    "print(f\"finanly we have {n} samples extracted features\")\n",
    "feats2 = np.array(feats)\n",
    "names2 = np.array(names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir ='/media/xingbo/Storage/fish_identification/data/SESSION_AQUARIUM/SESSION1_LT'\n",
    "BATCH_SIZE = 8\n",
    "testloadData = LoadFishDataUtil(test_data_dir,BATCH_SIZE,IMG_WIDTH,IMG_HEIGHT,CLASS_NAMES)\n",
    "sess2_test_dataset,sess2_class_num = testloadData.loadTestFishData()\n",
    "test_num_elements = tf.data.experimental.cardinality(sess2_test_dataset).numpy()\n",
    "print(f\"we have total {test_num_elements} batches of images for testing, around {test_num_elements*BATCH_SIZE} samples\")\n",
    "\n",
    "feats = []\n",
    "names = []\n",
    "feature_model = models.Model(inputs=model.input, outputs=model.get_layer('batch_normalization_13').output)\n",
    "n = 0\n",
    "for image_batch, label_batch in sess2_test_dataset:\n",
    "    feature=model(image_batch)\n",
    "    for i in range(feature.shape[0]):\n",
    "        n=n+1\n",
    "        feats.append(feature[i])\n",
    "        names.append(np.argwhere(label_batch[i]).ravel())\n",
    "        indxmax=np.argmax(feature[i])\n",
    "       \n",
    "print(f\"finanly we have {n} samples extracted features\")\n",
    "feats1 = np.array(feats)\n",
    "names1 = np.array(names)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asciiList = [n.encode(\"ascii\", \"ignore\") for n in names]\n",
    "# directory for storing extracted features\n",
    "feats_save_path = '/media/xingbo/Storage/fish_identification/data/merge3session.h5'\n",
    "print (\"--------------------------------------------------\")\n",
    "print (\"      writing feature extraction results ...\")\n",
    "print (\"--------------------------------------------------\")\n",
    "\n",
    "h5f = h5py.File(feats_save_path, 'w')\n",
    "h5f.create_dataset('Session3_features_merge3session', data=feats3)\n",
    "h5f.create_dataset('Session3_names_merge3session', data=names3)\n",
    "\n",
    "h5f.create_dataset('Session2_features_merge3session', data=feats2)\n",
    "h5f.create_dataset('Session2_names_merge3session', data=names2)\n",
    "\n",
    "h5f.create_dataset('Session1_features_merge3session', data=feats1)\n",
    "h5f.create_dataset('Session1_names_merge3session', data=names1)\n",
    "\n",
    "np.save('/media/xingbo/Storage/fish_identification/data/CLASS_NAMES.npy', CLASS_NAMES)\n",
    "\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feats_save_path = '/media/xingbo/Storage/fish_identification/data/merge3session.h5'\n",
    "print (\"--------------------------------------------------\")\n",
    "print (\"      reading feature extraction results ...\")\n",
    "print (\"--------------------------------------------------\")\n",
    "\n",
    "h5f = h5py.File(feats_save_path, 'r')\n",
    "Session1_features = h5f['Session1_features_merge3session'][:]\n",
    "Session1_names = h5f['Session1_names_merge3session'][:]\n",
    "\n",
    "Session2_features = h5f['Session2_features_merge3session'][:]\n",
    "Session2_names = h5f['Session2_names_merge3session'][:]\n",
    "\n",
    "Session3_features = h5f['Session3_features_merge3session'][:]\n",
    "Session3_names = h5f['Session3_names_merge3session'][:]\n",
    "\n",
    "h5f.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# matching session1 vs session 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract query image's feature, compute simlarity score and sort\n",
    "scores = np.dot(Session1_features, Session2_features.T)\n",
    "print(scores.shape)\n",
    "from numpy.linalg import norm\n",
    "res = 1 - np.dot(Session1_features/norm(Session1_features, axis=1)[...,None],(Session2_features/norm(Session2_features,axis=1)[...,None]).T)\n",
    "res = 1-res/2\n",
    "lable = Session1_names == Session2_names.T\n",
    "lable2 = Session1_names != Session2_names.T\n",
    "\n",
    "gscores=res[lable]\n",
    "print(gscores.shape)\n",
    "iscores=res[lable2]\n",
    "print(iscores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bob.measure\n",
    "iscores1vs2 = iscores.astype('float64')\n",
    "gscores1vs2=gscores.astype('float64') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EER = bob.measure.eer(iscores1vs2, gscores1vs2)\n",
    "print(f\"we can achieve EER with {EER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "# we assume you have your negatives and positives already split\n",
    "npoints = 100\n",
    "bob.measure.plot.roc(iscores1vs2, gscores1vs2, npoints, color=(0,0,0), linestyle='-', label='test') \n",
    "pyplot.xlabel('FPR (%)') \n",
    "pyplot.ylabel('FNR (%)') \n",
    "pyplot.grid(True)\n",
    "pyplot.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# matching session1 vs session 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract query image's feature, compute simlarity score and sort\n",
    "scores = np.dot(Session1_features, Session3_features.T)\n",
    "print(scores.shape)\n",
    "from numpy.linalg import norm\n",
    "res = 1 - np.dot(Session1_features/norm(Session1_features, axis=1)[...,None],(Session3_features/norm(Session3_features,axis=1)[...,None]).T)\n",
    "res = 1-res/2\n",
    "lable = Session1_names == Session3_names.T\n",
    "lable2 = Session1_names != Session3_names.T\n",
    "\n",
    "gscores=res[lable]\n",
    "print(gscores.shape)\n",
    "iscores=res[lable2]\n",
    "print(iscores.shape)\n",
    "\n",
    "import bob.measure\n",
    "iscores1vs3 = iscores.astype('float64')\n",
    "gscores1vs3=gscores.astype('float64') \n",
    "EER = bob.measure.eer(iscores1vs3, gscores1vs3)\n",
    "print(f\"we can achieve EER with {EER}\")\n",
    "from matplotlib import pyplot\n",
    "# we assume you have your negatives and positives already split\n",
    "npoints = 100\n",
    "bob.measure.plot.roc(iscores1vs3, gscores1vs3, npoints, color=(0,0,0), linestyle='-', label='test') \n",
    "pyplot.xlabel('FPR (%)') \n",
    "pyplot.ylabel('FNR (%)') \n",
    "pyplot.grid(True)\n",
    "pyplot.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# matching session2 vs session 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract query image's feature, compute simlarity score and sort\n",
    "scores = np.dot(Session2_features, Session3_features.T)\n",
    "print(scores.shape)\n",
    "from numpy.linalg import norm\n",
    "res = 1 - np.dot(Session2_features/norm(Session2_features, axis=1)[...,None],(Session3_features/norm(Session3_features,axis=1)[...,None]).T)\n",
    "res = 1-res/2\n",
    "lable = Session2_names == Session3_names.T\n",
    "lable2 = Session2_names != Session3_names.T\n",
    "\n",
    "gscores=res[lable]\n",
    "print(gscores.shape)\n",
    "iscores=res[lable2]\n",
    "print(iscores.shape)\n",
    "\n",
    "import bob.measure\n",
    "iscores2vs3 = iscores.astype('float64')\n",
    "gscores2vs3=gscores.astype('float64') \n",
    "EER = bob.measure.eer(iscores2vs3, gscores2vs3)\n",
    "print(f\"we can achieve EER with {EER}\")\n",
    "from matplotlib import pyplot\n",
    "# we assume you have your negatives and positives already split\n",
    "npoints = 100\n",
    "bob.measure.plot.roc(iscores2vs3, gscores2vs3, npoints, color=(0,0,0), linestyle='-', label='test') \n",
    "pyplot.xlabel('FPR (%)') \n",
    "pyplot.ylabel('FNR (%)') \n",
    "pyplot.grid(True)\n",
    "pyplot.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "# we assume you have your negatives and positives already split\n",
    "npoints = 100\n",
    "bob.measure.plot.roc(iscores1vs2, gscores1vs2, npoints, color=(0,0,0), linestyle='-', label='1 vs 2') \n",
    "bob.measure.plot.roc(iscores1vs3, gscores1vs3, npoints, color=(0,0,0), linestyle='-.', label='1 vs 3') \n",
    "bob.measure.plot.roc(iscores2vs3, gscores2vs3, npoints, color=(0,0,0), linestyle=':', label='2 vs 3') \n",
    "pyplot.xlabel('FPR (%)') \n",
    "pyplot.ylabel('FNR (%)') \n",
    "pyplot.legend()\n",
    "pyplot.grid(True)\n",
    "pyplot.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# intra session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bob.measure\n",
    "from matplotlib import pyplot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "\n",
    "\n",
    "res = 1 - np.dot(Session1_features/norm(Session1_features, axis=1)[...,None],(Session1_features/norm(Session1_features,axis=1)[...,None]).T)\n",
    "res = 1-res/2\n",
    "lable = Session1_names == Session1_names.T\n",
    "lable2 = Session1_names != Session1_names.T\n",
    "\n",
    "gscores=res[lable]\n",
    "iscores=res[lable2]\n",
    "\n",
    "iscores1vs1 = iscores.astype('float64')\n",
    "gscores1vs1=gscores.astype('float64') \n",
    "EER1vs1 = bob.measure.eer(iscores1vs1, gscores1vs1)\n",
    "print(f\"we can achieve EER with {EER1vs1}\")\n",
    "\n",
    "res = 1 - np.dot(Session2_features/norm(Session2_features, axis=1)[...,None],(Session2_features/norm(Session2_features,axis=1)[...,None]).T)\n",
    "res = 1-res/2\n",
    "lable = Session2_names == Session2_names.T\n",
    "lable2 = Session2_names != Session2_names.T\n",
    "\n",
    "gscores=res[lable]\n",
    "iscores=res[lable2]\n",
    "\n",
    "iscores2vs2 = iscores.astype('float64')\n",
    "gscores2vs2=gscores.astype('float64') \n",
    "EER2vs2 = bob.measure.eer(iscores2vs2, gscores2vs2)\n",
    "print(f\"we can achieve EER with {EER2vs2}\")\n",
    "\n",
    "res = 1 - np.dot(Session3_features/norm(Session3_features, axis=1)[...,None],(Session3_features/norm(Session3_features,axis=1)[...,None]).T)\n",
    "res = 1-res/2\n",
    "lable = Session3_names == Session3_names.T\n",
    "lable2 = Session3_names != Session3_names.T\n",
    "\n",
    "gscores=res[lable]\n",
    "iscores=res[lable2]\n",
    "\n",
    "iscores3vs3 = iscores.astype('float64')\n",
    "gscores3vs3=gscores.astype('float64') \n",
    "EER3vs3 = bob.measure.eer(iscores3vs3, gscores3vs3)\n",
    "print(f\"we can achieve EER with {EER3vs3}\")\n",
    "\n",
    "\n",
    "from matplotlib import pyplot\n",
    "# we assume you have your negatives and positives already split\n",
    "npoints = 100\n",
    "bob.measure.plot.roc(iscores1vs1, gscores1vs1, npoints, color=(0,0,0), linestyle='-', label='inta-session1') \n",
    "bob.measure.plot.roc(iscores2vs2, gscores2vs2, npoints, color=(0,0,0), linestyle='-.', label='inta-session2') \n",
    "bob.measure.plot.roc(iscores3vs3, gscores3vs3, npoints, color=(0,0,0), linestyle=':', label='inta-session3') \n",
    "pyplot.xlabel('FPR (%)') \n",
    "pyplot.ylabel('FNR (%)') \n",
    "pyplot.legend()\n",
    "pyplot.grid(True)\n",
    "pyplot.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
