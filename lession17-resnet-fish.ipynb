{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  os\n",
    "import  tensorflow as tf\n",
    "import  numpy as np\n",
    "import utils \n",
    "from tensorflow import keras\n",
    "from utils import LoadFishDataUtil\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,array_to_img,img_to_array,load_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir ='/media/xingbo/Storage/fish_identification/data/SESSION_AQUARIUM/SESSION_TRAIN'\n",
    "BATCH_SIZE = 8\n",
    "SPLIT_WEIGHTS = (0.7, 0.15, 0.15) # Data prepare split wight train vs validation vs test\n",
    "IMG_WIDTH=320\n",
    "IMG_HEIGHT=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "myloadData = LoadFishDataUtil(data_dir,BATCH_SIZE,IMG_WIDTH,IMG_HEIGHT)\n",
    "train_dataset,val_dataset,test_dataset,STEPS_PER_EPOCH, CLASS_NAMES,class_num = myloadData.loadFishData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3x3 convolution\n",
    "def conv3x3(channels, stride=1, kernel=(3, 3)):\n",
    "    return keras.layers.Conv2D(channels, kernel, strides=stride, padding='same',\n",
    "                               use_bias=False,\n",
    "                            kernel_initializer=tf.random_normal_initializer())\n",
    "\n",
    "class ResnetBlock(keras.Model):\n",
    "\n",
    "    def __init__(self, channels, strides=1, residual_path=False):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "\n",
    "        self.channels = channels\n",
    "        self.strides = strides\n",
    "        self.residual_path = residual_path\n",
    "\n",
    "        self.conv1 = conv3x3(channels, strides)\n",
    "        self.bn1 = keras.layers.BatchNormalization()\n",
    "        self.conv2 = conv3x3(channels)\n",
    "        self.bn2 = keras.layers.BatchNormalization()\n",
    "\n",
    "        if residual_path:\n",
    "            self.down_conv = conv3x3(channels, strides, kernel=(1, 1))\n",
    "            self.down_bn = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        residual = inputs\n",
    "\n",
    "        x = self.bn1(inputs, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn2(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        # this module can be added into self.\n",
    "        # however, module in for can not be added.\n",
    "        if self.residual_path:\n",
    "            residual = self.down_bn(inputs, training=training)\n",
    "            residual = tf.nn.relu(residual)\n",
    "            residual = self.down_conv(residual)\n",
    "\n",
    "        x = x + residual\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNet(keras.Model):\n",
    "\n",
    "    def __init__(self, block_list, num_classes, initial_filters=16, **kwargs):\n",
    "        super(ResNet, self).__init__(**kwargs)\n",
    "\n",
    "        self.num_blocks = len(block_list)\n",
    "        self.block_list = block_list\n",
    "\n",
    "        self.in_channels = initial_filters\n",
    "        self.out_channels = initial_filters\n",
    "        self.conv_initial = conv3x3(self.out_channels)\n",
    "\n",
    "        self.blocks = keras.models.Sequential(name='dynamic-blocks')\n",
    "\n",
    "        # build all the blocks\n",
    "        for block_id in range(len(block_list)):\n",
    "            for layer_id in range(block_list[block_id]):\n",
    "\n",
    "                if block_id != 0 and layer_id == 0:\n",
    "                    block = ResnetBlock(self.out_channels, strides=2, residual_path=True)\n",
    "                else:\n",
    "                    if self.in_channels != self.out_channels:\n",
    "                        residual_path = True\n",
    "                    else:\n",
    "                        residual_path = False\n",
    "                    block = ResnetBlock(self.out_channels, residual_path=residual_path)\n",
    "\n",
    "                self.in_channels = self.out_channels\n",
    "\n",
    "                self.blocks.add(block)\n",
    "\n",
    "            self.out_channels *= 2\n",
    "\n",
    "        self.final_bn = keras.layers.BatchNormalization()\n",
    "        self.avg_pool = keras.layers.GlobalAveragePooling2D()\n",
    "        self.fc = keras.layers.Dense(num_classes)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "\n",
    "        out = self.conv_initial(inputs)\n",
    "\n",
    "        out = self.blocks(out, training=training)\n",
    "\n",
    "        out = self.final_bn(out, training=training)\n",
    "        out = tf.nn.relu(out)\n",
    "\n",
    "        out = self.avg_pool(out)\n",
    "        out = self.fc(out)\n",
    "\n",
    "\n",
    "        return out\n",
    "\n",
    "# In[3]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = class_num\n",
    "epochs = 20\n",
    "validation_steps = 20\n",
    "# build model and optimizer\n",
    "model = ResNet([2, 2, 2], num_classes)\n",
    "model.compile(optimizer=keras.optimizers.Adam(0.001),\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),#TripletSemiHardLoss\n",
    "              metrics=['accuracy'])\n",
    "model.build(input_shape=(None, IMG_WIDTH,IMG_HEIGHT, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of variables in the model :\", len(model.variables))\n",
    "model.summary()\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "# This callback will stop the training when there is no improvement in\n",
    "# the validation loss for three consecutive epochs.\n",
    "# train\n",
    "history=model.fit(train_dataset, epochs=epochs,callbacks=[callback],\n",
    "          validation_data=val_dataset, verbose=1, validation_steps=validation_steps)\n",
    "\n",
    "# evaluate on test set\n",
    "scores = model.evaluate(test_dataset, verbose=1)\n",
    "print(\"Final test loss and accuracy :\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "# model.save('vggfish.h5py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('resnetfish20191120.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('resnetfish20191120.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# evaluate on test set\n",
    "scores = model.evaluate(test_dataset, verbose=1)\n",
    "print(\"Final test loss and accuracy :\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir ='/media/xingbo/Storage/fish_identification/data/SESSION_AQUARIUM/SESSION2'\n",
    "BATCH_SIZE = 8\n",
    "testloadData = LoadFishDataUtil(test_data_dir,BATCH_SIZE,IMG_WIDTH,IMG_HEIGHT,CLASS_NAMES)\n",
    "sess2_test_dataset,sess2_class_num = testloadData.loadTestFishData()\n",
    "\n",
    "sess2_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss0,accuracy0 = model.evaluate(sess2_test_dataset, steps = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "#img = image.load_img('/media/xingbo/Storage/fish_identification/data/SESSION_AQUARIUM/SESSION1/02883A/fish_2_02883A__4.png', target_size=(IMG_WIDTH,IMG_HEIGHT))\n",
    "img = image.load_img('/media/xingbo/Storage/fish_identification/data/SESSION_AQUARIUM/SESSION2/02883A/fish_2_02883A__03.png', target_size=(IMG_WIDTH,IMG_HEIGHT))\n",
    "#img = image.load_img('/media/xingbo/Storage/fish_identification/data/SESSION_AQUARIUM/SESSION3/02883A/fish_2_02883A_04.png', target_size=(IMG_WIDTH,IMG_HEIGHT))\n",
    "#plt.figure()\n",
    "#plt.imshow(img)\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x=x/255\n",
    "predictions = model(x)\n",
    "indxmax=np.argmax(predictions)\n",
    "print('predictions:', CLASS_NAMES[indxmax] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for x,y in sess2_train_dataset:\n",
    "    predictions = model.predict(x)\n",
    "    #print(predictions[0])\n",
    "    #print('predictions shape:', predictions.shape)\n",
    "    print('x shape:', x.shape)\n",
    "    for n in range(8):\n",
    "        indxmax=np.argmax(predictions[n])\n",
    "        #print('predictions max index:',indxmax)\n",
    "        print('predictions:', CLASS_NAMES[indxmax] )\n",
    "        print('real:', CLASS_NAMES[np.argwhere(y[n]).ravel()] )\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
